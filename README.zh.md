# HCEF-LLM: 大语言模型人本评估框架

[English](README.md) | [中文](README.zh.md)

## 🎯 项目概述

HCEF-LLM（大语言模型人本评估框架）是一个综合性评估框架，旨在从以人为中心的角度评估大语言模型作为"理想智能伙伴"的能力。本项目包含一个交互式的基于网页的排行榜和可视化平台，用于比较模型在多个维度上的性能。

## 🌟 功能特色

- **📊 交互式排行榜**：基于综合评估指标的LLM实时排名
- **📈 高级可视化**：包括雷达图、热力图和散点图在内的多种图表类型
- **🌐 双语支持**：完整的中英文语言支持
- **📱 响应式设计**：针对桌面和移动设备优化
- **🎨 现代化界面**：简洁专业的界面设计，配有流畅动画

## 🏗️ 框架结构

### 理想智能伙伴特征 (IIP)

1. **IIP1: 智能水平** - 具备高水平的认知、推理和问题解决能力
2. **IIP2: 人本导向** - 以人为中心，理解并适应人类需求
3. **IIP3: 伙伴关系** - 建立积极、互补的协作关系
4. **IIP4: 可靠性** - 表现稳定，输出可靠且一致
5. **IIP5: 适应性** - 能够灵活应对不同场景和需求变化
6. **IIP6: 安全性** - 确保交互安全，保护用户隐私

### 核心能力维度 (CD)

1. **CD1: 输入处理与理解** - 理解和处理各种输入格式的能力
   - 文本理解
   - 上下文把握
   - 指令解析
   - 多模态输入处理

2. **CD2: 知识保持与应用** - 保持和应用所学知识的能力
   - 知识储备
   - 信息检索
   - 知识整合
   - 实践应用

3. **CD3: 逻辑推理与问题解决** - 逻辑分析和问题解决技能
   - 因果推理
   - 逻辑分析
   - 问题分解
   - 方案优化

4. **CD4: 想象与创造性认知** - 创造性思维和创新问题解决方法
   - 创意生成
   - 跨领域联想
   - 新颖性思考
   - 创新应用

5. **CD5: 以人为中心与伦理对齐** - 与人类价值观和伦理考量的对齐
   - 价值观对齐
   - 伦理意识
   - 安全边界
   - 隐私保护

6. **CD6: 输出生成与交付** - 生成响应的质量和有效性
   - 表达清晰
   - 格式规范
   - 质量控制
   - 效果评估

### 熟练度描述符 (PD)

#### PD1: 新兴
- **特征**：基本功能，存在显著限制
- **表现**：
  - 只能处理简单、明确的任务
  - 需要详细的指导和结构化输入
  - 输出质量不稳定
  - 有限的错误处理能力

#### PD2: 发展中
- **特征**：能力提升，存在一些约束
- **表现**：
  - 可以处理中等复杂度的任务
  - 需要适度的指导
  - 输出质量逐步提高
  - 基本的错误处理能力

#### PD3: 熟练
- **特征**：稳定性能，满足大多数要求
- **表现**：
  - 能够处理复杂任务
  - 较强的自主性
  - 输出质量稳定
  - 良好的错误处理能力

#### PD4: 专家
- **特征**：卓越性能，超越预期
- **表现**：
  - 能够处理高度复杂的任务
  - 极强的自主性和创造力
  - 输出质量优异
  - 出色的错误处理和恢复能力

## 📊 评估结果

排行榜包含各种最先进语言模型的评估结果：

- GPT-4 Turbo
- Claude 3.5 Sonnet
- Gemini 1.5 Pro
- GPT-4o
- Claude 3 Opus
- Llama 3.1 405B
- 等等...

每个模型都在所有六个能力维度上进行评估，并被分配一个整体熟练度等级。

## 👥 作者

- **王平凡** - 研究负责人
- **邓林远** - 技术实现 (dolly_dev@163.com)

## 📚 引用

如果您在研究中使用此框架，请引用：

```bibtex
@article{wang2024hcef,
  title={HCEF-LLM: Human-Centric Evaluation Framework for Large Language Models as Ideal Intelligent Partners},
  author={Wang, Pingfan and Deng, Linyuan},
  year={2024}
}
```