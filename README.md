# HCEF-LLM: Human-Centric Evaluation Framework for Large Language Models

[English](README.md) | [‰∏≠Êñá](README.zh.md)

## üéØ Overview

HCEF-LLM (Human-Centric Evaluation Framework for Large Language Models) is a comprehensive evaluation framework designed to assess Large Language Models as "Ideal Intelligent Partners" from a human-centric perspective. This project contains an interactive web-based leaderboard and visualization platform for comparing model performance across multiple dimensions.

## üåü Features

- **üìä Interactive Leaderboard**: Real-time ranking of LLMs based on comprehensive evaluation metrics
- **üìà Advanced Visualizations**: Multiple chart types including radar charts, heatmaps, and scatter plots
- **üåê Bilingual Support**: Full English and Chinese language support
- **üì± Responsive Design**: Optimized for desktop and mobile devices
- **üé® Modern UI**: Clean, professional interface with smooth animations

## üèóÔ∏è Framework Structure

### Ideal Intelligent Partner Properties (IIP)

1. **IIP1: Intelligence Level** - High-level cognitive, reasoning, and problem-solving capabilities
2. **IIP2: Human-Oriented** - Human-centric understanding and adaptation
3. **IIP3: Partnership** - Positive and complementary collaborative relationship
4. **IIP4: Reliability** - Stable performance with reliable and consistent output
5. **IIP5: Adaptability** - Flexible response to different scenarios and changing needs
6. **IIP6: Security** - Ensuring interaction safety and user privacy protection

### Core Capability Dimensions (CD)

1. **CD1: Input Processing & Comprehension** - Ability to understand and process various input formats
   - Text comprehension
   - Context understanding
   - Instruction parsing
   - Multimodal input processing

2. **CD2: Knowledge Retention & Application** - Capacity to retain and apply learned knowledge
   - Knowledge base
   - Information retrieval
   - Knowledge integration
   - Practical application

3. **CD3: Logical Reasoning & Problem Solving** - Skills in logical analysis and problem resolution
   - Causal reasoning
   - Logical analysis
   - Problem decomposition
   - Solution optimization

4. **CD4: Imaginative & Creative Cognition** - Creative thinking and innovative problem approaches
   - Idea generation
   - Cross-domain association
   - Novel thinking
   - Innovation application

5. **CD5: Human-Centricity & Ethical Alignment** - Alignment with human values and ethical considerations
   - Value alignment
   - Ethical awareness
   - Safety boundaries
   - Privacy protection

6. **CD6: Output Generation & Delivery** - Quality and effectiveness of generated responses
   - Clear expression
   - Format compliance
   - Quality control
   - Effect evaluation

### Proficiency Descriptors (PD)

#### PD1: Emergent
- **Characteristics**: Basic functionality with significant limitations
- **Performance**:
  - Can only handle simple, explicit tasks
  - Requires detailed guidance and structured input
  - Unstable output quality
  - Limited error handling capabilities

#### PD2: Developing
- **Characteristics**: Improving capabilities with some constraints
- **Performance**:
  - Can handle moderately complex tasks
  - Requires moderate guidance
  - Gradually improving output quality
  - Basic error handling capabilities

#### PD3: Proficient
- **Characteristics**: Solid performance meeting most requirements
- **Performance**:
  - Can handle complex tasks
  - Strong autonomy
  - Stable output quality
  - Good error handling capabilities

#### PD4: Expert
- **Characteristics**: Exceptional performance exceeding expectations
- **Performance**:
  - Can handle highly complex tasks
  - Exceptional autonomy and creativity
  - Excellent output quality
  - Outstanding error handling and recovery capabilities

## üìä Evaluation Results

The leaderboard includes evaluation results for various state-of-the-art language models:

- GPT-4 Turbo
- Claude 3.5 Sonnet
- Gemini 1.5 Pro
- GPT-4o
- Claude 3 Opus
- Llama 3.1 405B
- And more...

Each model is evaluated across all six capability dimensions and assigned an overall proficiency level.

## üë• Authors

- **Pingfan Wang** - Research Lead
- **Linyuan Deng** - Technical Implementation (dolly_dev@163.com)

## üìö Citation

If you use this framework in your research, please cite:

```bibtex
@article{wang2024hcef,
  title={HCEF-LLM: Human-Centric Evaluation Framework for Large Language Models as Ideal Intelligent Partners},
  author={Wang, Pingfan and Deng, Linyuan},
  year={2024}
}
```